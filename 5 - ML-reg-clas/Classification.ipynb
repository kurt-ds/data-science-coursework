{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Assignment\n",
    "\n",
    "**Name:** Allen Kurt Delos Santos \n",
    "\n",
    "**Course & Section:** BSCS-ML - COM221 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlkudcoiQFGz"
   },
   "source": [
    "### **Classification using sklearn and keras (with pandas)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I77EPVwDRJaO"
   },
   "source": [
    "<font color=\"red\">File access required:</font> In Colab this notebook requires first uploading files **Cities.csv**, **Players.csv**, and **Titanic.csv** using the *Files* feature in the left toolbar. If running the notebook on a local computer, simply ensure these files are in the same workspace as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (6.33.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\windows 11\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow (run this cell once, then you can comment it out or delete it)\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MSS0u6TNQFG1"
   },
   "outputs": [],
   "source": [
    "# Set-up\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from numpy.random import seed\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxof3bb4QFG2"
   },
   "source": [
    "### Prepare Cities data for classification\n",
    "Predict <i>temperature category</i> from other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738391553463,
     "user": {
      "displayName": "Manolito Jr. Octaviano",
      "userId": "01566897500508849541"
     },
     "user_tz": -480
    },
    "id": "720BLLytQFG3",
    "outputId": "8887b1a6-add8-49bf-b358-f1378477b279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold: 17\n",
      "cool: 92\n",
      "warm: 79\n",
      "hot: 25\n"
     ]
    }
   ],
   "source": [
    "# Read Cities.csv into dataframe, add column for temperature category\n",
    "# Note: For a dataframe D and integer i, D.loc[i] is the i-th row of D\n",
    "f = open('Cities.csv')\n",
    "cities = pd.read_csv(f)\n",
    "categories = []\n",
    "for i in range(len(cities)):\n",
    "    if cities.loc[i]['temperature'] < 5:\n",
    "        categories.append('cold')\n",
    "    elif cities.loc[i]['temperature'] < 9:\n",
    "        categories.append('cool')\n",
    "    elif cities.loc[i]['temperature'] < 15:\n",
    "        categories.append('warm')\n",
    "    else: categories.append('hot')\n",
    "cities['category'] = categories\n",
    "print(\"cold:\", len(cities[(cities.category == 'cold')]))\n",
    "print(\"cool:\", len(cities[(cities.category == 'cool')]))\n",
    "print(\"warm:\", len(cities[(cities.category == 'warm')]))\n",
    "print(\"hot:\", len(cities[(cities.category == 'hot')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1738391596377,
     "user": {
      "displayName": "Manolito Jr. Octaviano",
      "userId": "01566897500508849541"
     },
     "user_tz": -480
    },
    "id": "Tu_bmPoSQFG3",
    "outputId": "a4adfa21-403f-463a-81cc-eeb4c93794b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 181 items\n",
      "Test set 32 items\n"
     ]
    }
   ],
   "source": [
    "# Create training and test sets for cities data\n",
    "numitems = len(cities)\n",
    "percenttrain = 0.85\n",
    "numtrain = int(numitems*percenttrain)\n",
    "\n",
    "print('Training set', numtrain, 'items')\n",
    "print('Test set', numitems - numtrain, 'items')\n",
    "\n",
    "citiesTrain = cities[0:numtrain]\n",
    "citiesTest = cities[numtrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1Dr0WxgQFG4"
   },
   "source": [
    "### K-nearest-neighbors classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1738391811276,
     "user": {
      "displayName": "Manolito Jr. Octaviano",
      "userId": "01566897500508849541"
     },
     "user_tz": -480
    },
    "id": "xHDKqC1vQFG4",
    "outputId": "1f771ea4-b719-4dac-e028-1432a7dfb6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: warm  Actual: cool\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: hot  Actual: warm\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: cold  Actual: cool\n",
      "Predicted: cool  Actual: cool\n",
      "Predicted: cool  Actual: cool\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: cool  Actual: cold\n",
      "Predicted: cold  Actual: cold\n",
      "Predicted: cool  Actual: warm\n",
      "Predicted: cool  Actual: cold\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: cool  Actual: warm\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: hot  Actual: hot\n",
      "Predicted: cold  Actual: cold\n",
      "Predicted: cold  Actual: cold\n",
      "Predicted: cool  Actual: cold\n",
      "Predicted: hot  Actual: hot\n",
      "Predicted: warm  Actual: cool\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: cool  Actual: cool\n",
      "Predicted: cool  Actual: cool\n",
      "Predicted: cool  Actual: cool\n",
      "Predicted: cool  Actual: warm\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: cool  Actual: cool\n",
      "Predicted: warm  Actual: warm\n",
      "Predicted: cool  Actual: cool\n",
      "Accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "features = ['longitude', 'latitude']\n",
    "neighbors = 3\n",
    "predict = 'category'\n",
    "\n",
    "classifier = KNeighborsClassifier(neighbors)\n",
    "classifier.fit(citiesTrain[features], citiesTrain[predict])\n",
    "\n",
    "\n",
    "predictions = classifier.predict(citiesTest[features])\n",
    "\n",
    "# Calculate accuracy\n",
    "actuals = list(citiesTest[predict])\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(actuals)):\n",
    "  print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))\n",
    "# Comment out print, try different values for neighbors, different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryRTSCCgQFG5"
   },
   "source": [
    "### <font color=\"green\">**Your Turn: K-nearest-neighbors on World Cup data**</font>\n",
    "<font color=\"green\">Predict <i>position</i> from one or more of <i>minutes, shots, passes, tackles, saves</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "77MKHzLtQFG5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 547 items\n",
      "Test set 48 items\n"
     ]
    }
   ],
   "source": [
    "# This cell does all the set-up, including reordering the data to avoid team bias.\n",
    "f = open('Players.csv')\n",
    "players = pd.read_csv(f)\n",
    "players = players.sort_values(by='surname')\n",
    "players = players.reset_index(drop=True)\n",
    "numitems = len(players)\n",
    "percenttrain = 0.92\n",
    "numtrain = int(numitems*percenttrain)\n",
    "print('Training set', numtrain, 'items')\n",
    "print('Test set', numitems - numtrain, 'items')\n",
    "playersTrain = players[0:numtrain]\n",
    "playersTest = players[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Qopw48z3QFG5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: goalkeeper  Actual: goalkeeper\n",
      "Predicted: forward  Actual: midfielder\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: midfielder  Actual: forward\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: defender  Actual: forward\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: midfielder  Actual: defender\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: goalkeeper  Actual: goalkeeper\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: defender  Actual: forward\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: forward  Actual: midfielder\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: defender  Actual: midfielder\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: forward  Actual: midfielder\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: forward  Actual: midfielder\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: goalkeeper  Actual: forward\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: midfielder  Actual: defender\n",
      "Predicted: defender  Actual: midfielder\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: midfielder  Actual: forward\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: defender  Actual: midfielder\n",
      "Predicted: defender  Actual: midfielder\n",
      "Predicted: midfielder  Actual: midfielder\n",
      "Predicted: defender  Actual: defender\n",
      "Predicted: forward  Actual: forward\n",
      "Predicted: defender  Actual: defender\n",
      "Accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "# This cell does the classification.\n",
    "# Try different features and different numbers of neighbors.\n",
    "# What's the highest accuracy you can get?\n",
    "features = ['tackles', 'shots']\n",
    "neighbors = 3\n",
    "predict = 'position'\n",
    "classifier = KNeighborsClassifier(neighbors)\n",
    "classifier.fit(playersTrain[features], playersTrain[predict])\n",
    "predictions = classifier.predict(playersTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(playersTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "  print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))\n",
    "# Comment out print, try different values for neighbors, different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAgMoPCsQFG6"
   },
   "source": [
    "### <font color=\"green\">**Your Turn Extra: K-nearest-neighbors on Titanic data - Graded**</font>\n",
    "<font color=\"green\">Predict <i>survived</i> from one or more of <i>gender, age, class, fare, embarked</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ssmntMEJQFG6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 819 items\n",
      "Test set 72 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\windows 11\\AppData\\Local\\Temp\\ipykernel_35660\\257007092.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['gender'].replace({'M':0, 'F':1}, inplace=True)\n",
      "C:\\Users\\windows 11\\AppData\\Local\\Temp\\ipykernel_35660\\257007092.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  titanic['gender'].replace({'M':0, 'F':1}, inplace=True)\n",
      "C:\\Users\\windows 11\\AppData\\Local\\Temp\\ipykernel_35660\\257007092.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['embarked'].replace({'Cherbourg':0, 'Southampton':1, 'Queenstown':2}, inplace=True)\n",
      "C:\\Users\\windows 11\\AppData\\Local\\Temp\\ipykernel_35660\\257007092.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  titanic['embarked'].replace({'Cherbourg':0, 'Southampton':1, 'Queenstown':2}, inplace=True)\n",
      "C:\\Users\\windows 11\\AppData\\Local\\Temp\\ipykernel_35660\\257007092.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['age'].fillna(avg_age, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# This cell does all the set-up\n",
    "f = open('Titanic.csv')\n",
    "titanic = pd.read_csv(f)\n",
    "# Convert gender and embarked to numeric values and missing ages to average age\n",
    "titanic['gender'].replace({'M':0, 'F':1}, inplace=True)\n",
    "titanic['embarked'].replace({'Cherbourg':0, 'Southampton':1, 'Queenstown':2}, inplace=True)\n",
    "avg_age = np.average(titanic['age'].dropna().tolist())\n",
    "titanic['age'].fillna(avg_age, inplace=True)\n",
    "# Create training and test sets\n",
    "numitems = len(titanic)\n",
    "percenttrain = 0.92\n",
    "numtrain = int(numitems*percenttrain)\n",
    "print('Training set', numtrain, 'items')\n",
    "print('Test set', numitems - numtrain, 'items')\n",
    "titanicTrain = titanic[0:numtrain]\n",
    "titanicTest = titanic[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1QkwNrbWQFG7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86111\n"
     ]
    }
   ],
   "source": [
    "# This cell does the classification.\n",
    "# Try different features and different numbers of neighbors.\n",
    "# What's the highest accuracy you can get?\n",
    "features = ['gender', 'class']\n",
    "neighbors = 3\n",
    "predict = 'survived'\n",
    "classifier = KNeighborsClassifier(neighbors)\n",
    "classifier.fit(titanicTrain[features], titanicTrain[predict])\n",
    "predictions = classifier.predict(titanicTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(titanicTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHUjWT6KQFG7"
   },
   "source": [
    "### Decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1738392063927,
     "user": {
      "displayName": "Manolito Jr. Octaviano",
      "userId": "01566897500508849541"
     },
     "user_tz": -480
    },
    "id": "A7X76CrJQFG8",
    "outputId": "3ab9f8f3-0502-4a0c-d1aa-073e733f61ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65625\n"
     ]
    }
   ],
   "source": [
    "features = ['longitude','latitude']\n",
    "split = 2\n",
    "predict = 'category'\n",
    "\n",
    "# random forest\n",
    "for x in range(1, 10):\n",
    "  dt = DecisionTreeClassifier(random_state=0, min_samples_split=split) # split parameter is optional\n",
    "  dt.fit(citiesTrain[features], citiesTrain[predict])\n",
    "\n",
    "  predictions = dt.predict(citiesTest[features])\n",
    "  # print(x ....)\n",
    "\n",
    "# aggregated predicted output\n",
    "\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "actuals = list(citiesTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))\n",
    "# Try different values for split, different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcYcgUoUQFG8"
   },
   "source": [
    "### \"Forest\" of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1738392208820,
     "user": {
      "displayName": "Manolito Jr. Octaviano",
      "userId": "01566897500508849541"
     },
     "user_tz": -480
    },
    "id": "butlqjoPQFG9",
    "outputId": "9f3e5adc-b080-4743-ee21-e38924294a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78125\n"
     ]
    }
   ],
   "source": [
    "features = ['longitude', 'latitude']\n",
    "split = 10\n",
    "trees = 10\n",
    "predict = 'category'\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, min_samples_split=split, n_estimators=trees)\n",
    "rf.fit(citiesTrain[features], citiesTrain[predict])\n",
    "\n",
    "\n",
    "predictions = rf.predict(citiesTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(citiesTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))\n",
    "# Try different values for split and trees, different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwIO1eBuQFG9"
   },
   "source": [
    "### <font color=\"green\">**Your Turn: Decision tree and forest of trees on World Cup data - Graded**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hAEWoJrnQFG9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77083\n"
     ]
    }
   ],
   "source": [
    "# SINGLE TREE\n",
    "# Try different features and different values for split.\n",
    "# What's the highest accuracy you can get?\n",
    "features = ['minutes', 'shots', 'tackles']\n",
    "split = 30\n",
    "predict = 'position'\n",
    "dt = DecisionTreeClassifier(random_state=0, min_samples_split=split) # parameter is optional\n",
    "dt.fit(playersTrain[features], playersTrain[predict])\n",
    "predictions = dt.predict(playersTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(playersTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "d8OY9PX2QFG-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "# FOREST OF TREES\n",
    "# Try different features and different values for split and trees.\n",
    "# What's the highest accuracy you can get?\n",
    "features = ['minutes', 'shots', 'passes', 'tackles']\n",
    "split = 40\n",
    "trees = 20\n",
    "predict = 'position'\n",
    "rf = RandomForestClassifier(random_state=0, min_samples_split=split, n_estimators=trees)\n",
    "rf.fit(playersTrain[features], playersTrain[predict])\n",
    "predictions = rf.predict(playersTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(playersTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_2L6LwCQFG-"
   },
   "source": [
    "### <font color=\"green\">**Your Turn Extra: Decision tree and forest of trees on Titanic data - Graded**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2D_Hvqm6QFG-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86111\n"
     ]
    }
   ],
   "source": [
    "# SINGLE TREE\n",
    "# Try different features and different values for split.\n",
    "# What's the highest accuracy you can get?\n",
    "features = ['gender', 'class', 'embarked']\n",
    "split = 2\n",
    "predict = 'survived'\n",
    "dt = DecisionTreeClassifier(random_state=0, min_samples_split=split) # parameter is optional\n",
    "dt.fit(titanicTrain[features], titanicTrain[predict])\n",
    "predictions = dt.predict(titanicTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(titanicTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ooLoMxE3QFG_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# FOREST OF TREES\n",
    "# Try different features and different values for split and trees.\n",
    "# What's the highest accuracy you can get?\n",
    "features = ['gender', 'class', 'fare', 'embarked']\n",
    "split = 80\n",
    "trees = 25\n",
    "predict = 'survived'\n",
    "rf = RandomForestClassifier(random_state=0, min_samples_split=split, n_estimators=trees)\n",
    "rf.fit(titanicTrain[features], titanicTrain[predict])\n",
    "predictions = rf.predict(titanicTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(titanicTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dmN5JQIQFG_"
   },
   "source": [
    "### Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1738392346333,
     "user": {
      "displayName": "Manolito Jr. Octaviano",
      "userId": "01566897500508849541"
     },
     "user_tz": -480
    },
    "id": "A8J8RFw_QFHA",
    "outputId": "dcdeedb7-edd3-4fc6-8b94-eb57ace5a520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78125\n"
     ]
    }
   ],
   "source": [
    "features = ['longitude', 'latitude']\n",
    "predict = 'category'\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(citiesTrain[features], citiesTrain[predict])\n",
    "\n",
    "predictions = nb.predict(citiesTest[features])\n",
    "\n",
    "# Calculate accuracy\n",
    "actuals = list(citiesTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))\n",
    "# Try different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZYntlrAQFHA"
   },
   "source": [
    "### <font color=\"green\">**Your Turn: Naive Bayes on World Cup data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "umcLV_4rQFHA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Try different features. What's the highest accuracy you can get?\n",
    "features = [ 'shots', 'passes', 'tackles', 'saves']\n",
    "predict = 'position'\n",
    "nb = GaussianNB()\n",
    "nb.fit(playersTrain[features], playersTrain[predict])\n",
    "predictions = nb.predict(playersTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(playersTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BJzyGiTQFHA"
   },
   "source": [
    "### <font color=\"green\">**Your Turn Extra: Naive Bayes on Titanic data - Graded**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "QVm0cp10QFHB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81944\n"
     ]
    }
   ],
   "source": [
    "# Try different features. What's the highest accuracy you can get?\n",
    "features = ['gender']\n",
    "predict = 'survived'\n",
    "nb = GaussianNB()\n",
    "nb.fit(titanicTrain[features], titanicTrain[predict])\n",
    "predictions = nb.predict(titanicTest[features])\n",
    "# Calculate accuracy\n",
    "actuals = list(titanicTest[predict])\n",
    "correct = 0\n",
    "for i in range(len(actuals)):\n",
    "# print('Predicted:', predictions[i], ' Actual:', actuals[i])\n",
    "  if predictions[i] == actuals[i]: correct +=1\n",
    "print('Accuracy:', round(correct/len(actuals),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXDh563OQFHB"
   },
   "source": [
    "### Neural network classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "O5WX8b_GQFHB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\windows 11\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 - 1s - 147ms/step - accuracy: 0.4530 - loss: 1.3451\n",
      "Epoch 2/10\n",
      "10/10 - 0s - 5ms/step - accuracy: 0.4530 - loss: 1.2788\n",
      "Epoch 3/10\n",
      "10/10 - 0s - 5ms/step - accuracy: 0.5304 - loss: 1.2208\n",
      "Epoch 4/10\n",
      "10/10 - 0s - 5ms/step - accuracy: 0.6575 - loss: 1.1587\n",
      "Epoch 5/10\n",
      "10/10 - 0s - 6ms/step - accuracy: 0.6685 - loss: 1.0958\n",
      "Epoch 6/10\n",
      "10/10 - 0s - 6ms/step - accuracy: 0.6685 - loss: 1.0340\n",
      "Epoch 7/10\n",
      "10/10 - 0s - 6ms/step - accuracy: 0.6685 - loss: 0.9789\n",
      "Epoch 8/10\n",
      "10/10 - 0s - 5ms/step - accuracy: 0.6630 - loss: 0.9311\n",
      "Epoch 9/10\n",
      "10/10 - 0s - 6ms/step - accuracy: 0.6796 - loss: 0.8914\n",
      "Epoch 10/10\n",
      "10/10 - 0s - 6ms/step - accuracy: 0.6906 - loss: 0.8557\n",
      "Number of epochs: 10\n",
      "Final accuracy on training data: 0.6906077265739441\n",
      "Accuracy on test data: 0.625\n"
     ]
    }
   ],
   "source": [
    "features = ['longitude', 'latitude']\n",
    "num_layers = 5 # including input and output, so must be >= 2\n",
    "num_epochs = 10 # number of iterations over training data\n",
    "batchsize = 20 # size of each batch during one iteration\n",
    "layer_outputs = 32 # dimensionality of output of each layer\n",
    "epoch_tracing = 'yes'\n",
    "predict = 'category'\n",
    "# Normalize feature values\n",
    "sc = StandardScaler()\n",
    "featurevals_train = sc.fit_transform(citiesTrain[features])\n",
    "featurevals_test = sc.fit_transform(citiesTest[features])\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(cities[predict])\n",
    "labels_train = encoder.transform(citiesTrain[predict])\n",
    "labels_test = encoder.transform(citiesTest[predict])\n",
    "# Set up neural-net classifier\n",
    "seed(1) # to eliminate some randomness\n",
    "tensorflow.random.set_seed(1) # to eliminate more randomness\n",
    "classifier = Sequential()\n",
    "# Input layer\n",
    "classifier.add(Dense(layer_outputs, activation='relu', input_dim=len(features)))\n",
    "\n",
    "# Hidden layers\n",
    "for i in range(num_layers-2):\n",
    "    classifier.add(Dense(layer_outputs, activation='relu',))\n",
    "\n",
    "\n",
    "# Output layer - first arg is number of labels, softmax for multi-class classification\n",
    "classifier.add(Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "classifier.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "# Fit to training data\n",
    "if epoch_tracing == 'yes': v = 2\n",
    "else: v = 0\n",
    "hist = classifier.fit(featurevals_train, labels_train, batch_size=batchsize, epochs=num_epochs, verbose=v)\n",
    "print('Number of epochs:', num_epochs)\n",
    "print('Final accuracy on training data:', hist.history['accuracy'][-1])\n",
    "# Evaluate on test data\n",
    "test_acc = classifier.evaluate(featurevals_test, labels_test, verbose=0)[1]\n",
    "print('Accuracy on test data:', test_acc)\n",
    "# Try different values for num_layers, num_epochs, batch size, layer_outputs, and different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W374RZM3QFHC"
   },
   "source": [
    "### <font color=\"green\">**Your Turn: Neural network on World Cup data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "g2sUnz0NQFHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 50\n",
      "Final accuracy on training data: 0.703839123249054\n",
      "Accuracy on test data: 0.7083333134651184\n"
     ]
    }
   ],
   "source": [
    "# Try different features and different values for num_layers, num_epochs,\n",
    "#  batch size, and layer_outputs.\n",
    "# What's the highest accuracy you can get?\n",
    "# Note: Although some randomness is removed by setting seeds in the code,\n",
    "#  you may still see somewhat different accuracy on different runs;\n",
    "#  changing the order of the features can also affect accuracy\n",
    "features = ['minutes', 'shots', 'passes', 'tackles', 'saves']\n",
    "num_layers = 4\n",
    "num_epochs = 50\n",
    "batchsize = 30\n",
    "layer_outputs = 64 # dimensionality of output of each layer\n",
    "epoch_tracing = 'no'\n",
    "predict = 'position'\n",
    "# Normalize feature values\n",
    "sc = StandardScaler()\n",
    "featurevals_train = sc.fit_transform(playersTrain[features])\n",
    "featurevals_test = sc.fit_transform(playersTest[features])\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(players[predict])\n",
    "labels_train = encoder.transform(playersTrain[predict])\n",
    "labels_test = encoder.transform(playersTest[predict])\n",
    "# Set up neural-net classifier\n",
    "seed(1) # to eliminate some randomness\n",
    "tensorflow.random.set_seed(1) # to eliminate more randomness\n",
    "classifier = Sequential()\n",
    "# Input layer\n",
    "classifier.add(Dense(layer_outputs, activation='relu', input_dim=len(features)))\n",
    "# Hidden layers\n",
    "for i in range(num_layers-2):\n",
    "    classifier.add(Dense(layer_outputs, activation='relu',))\n",
    "# Output layer - first arg is number of labels, softmax for multi-class classification\n",
    "classifier.add(Dense(4, activation='softmax'))\n",
    "classifier.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "# Fit to training data\n",
    "if epoch_tracing == 'yes': v = 2\n",
    "else: v = 0\n",
    "hist = classifier.fit(featurevals_train, labels_train, batch_size=batchsize, epochs=num_epochs, verbose=v)\n",
    "print('Number of epochs:', num_epochs)\n",
    "print('Final accuracy on training data:', hist.history['accuracy'][-1])\n",
    "# Evaluate on test data\n",
    "test_acc = classifier.evaluate(featurevals_test, labels_test, verbose=0)[1]\n",
    "print('Accuracy on test data:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEKxlWPxQFHC"
   },
   "source": [
    "### <font color=\"green\">**Your Turn Extra: Neural network on Titanic data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "0KYHOL58QFHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 20\n",
      "Final accuracy on training data: 0.8034188151359558\n",
      "Accuracy on test data: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Try different features and different values for num_layers, num_epochs,\n",
    "#  batch size, and layer_outputs.\n",
    "# What's the highest accuracy you can get?\n",
    "# Note: Although some randomness is removed by setting seeds in the code,\n",
    "#  you may still see somewhat different accuracy on different runs;\n",
    "#  changing the order of the features can also affect accuracy\n",
    "features = ['gender', 'class', 'fare']\n",
    "num_layers = 3 # including input and output, so must be >= 2\n",
    "num_epochs = 20 # number of iterations over training data\n",
    "batchsize = 20 # size of each batch during one iteration\n",
    "layer_outputs = 32 # dimensionality of output of each layer\n",
    "epoch_tracing = 'no'\n",
    "predict = 'survived'\n",
    "# Normalize feature values\n",
    "sc = StandardScaler()\n",
    "featurevals_train = sc.fit_transform(titanicTrain[features])\n",
    "featurevals_test = sc.fit_transform(titanicTest[features])\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(titanic[predict])\n",
    "labels_train = encoder.transform(titanicTrain[predict])\n",
    "labels_test = encoder.transform(titanicTest[predict])\n",
    "# Set up neural-net classifier\n",
    "seed(1) # to eliminate some randomness\n",
    "tensorflow.random.set_seed(1) # to eliminate more randomness\n",
    "classifier = Sequential()\n",
    "# Input layer\n",
    "classifier.add(Dense(layer_outputs, activation='relu', input_dim=len(features)))\n",
    "# Hidden layers\n",
    "for i in range(num_layers-2):\n",
    "    classifier.add(Dense(layer_outputs, activation='relu',))\n",
    "# Output layer - first arg is number of labels, softmax for multi-class classification\n",
    "classifier.add(Dense(4, activation='softmax'))\n",
    "classifier.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "# Fit to training data\n",
    "if epoch_tracing == 'yes': v = 2\n",
    "else: v = 0\n",
    "hist = classifier.fit(featurevals_train, labels_train, batch_size=batchsize, epochs=num_epochs, verbose=v)\n",
    "print('Number of epochs:', num_epochs)\n",
    "print('Final accuracy on training data:', hist.history['accuracy'][-1])\n",
    "# Evaluate on test data\n",
    "test_acc = classifier.evaluate(featurevals_test, labels_test, verbose=0)[1]\n",
    "print('Accuracy on test data:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
